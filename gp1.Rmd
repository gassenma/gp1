---
title: "HW6 Telemarketing"
author: "Gino Assenmacher, Johanna Langemeyer, Lukas Resch, Benjamin Roemer, Nathan Koenig"
date: "10/04/2022"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}

library(dplyr)

#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)

tele$pdays <- NULL
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

```


> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

```{r, cache=TRUE}

set.seed(12345)
test_set_ann <- sample(1:nrow(tele_norm), 10000)

tele_train_ann <- tele_norm[-test_set_ann,]
tele_test_ann <- tele_norm[test_set_ann,]

library(neuralnet)

#ann_model <- neuralnet(formula = yyes ~ ., data = tele_train_ann, hidden = c(5,3))

tele_test_ann$extra <- tele_test_ann$yyes
tele_test_ann$yyes <- NULL
names(tele_test_ann)[names(tele_test_ann) == 'extra'] <- "yyes" 

ann_results <- neuralnet::compute(ann_model, tele_test_ann[1:53])

predicted_strength <- ann_results$net.result

prediction_ann <- predict(ann_model, tele_test_ann)
yyes_prediction <- ifelse(prediction_ann < 0.5, 0, 1)

cor(predicted_strength, tele_test_ann$yyes)

```

```{r}

library(class)
library(caret)
library(gmodels)

CrossTable(x = tele_test_ann$yyes, y = yyes_prediction, prop.chisq = FALSE)
confusionMatrix(as.factor(yyes_prediction), as.factor(tele_test_ann$yyes), positive = "1")

```

## KNN MODEL

```{r}

# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
  }


# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train_knn <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test_knn <- tele_norm[test_set, -match("yyes",names(tele_norm))]

tele_train_knn <- as.data.frame(scale(tele_train_knn))
tele_test_knn <- as.data.frame(scale(tele_test_knn))

#Now the response (aka Labels) - only the yyes column
tele_train_knn_labels <- tele_norm[-test_set, "yyes"]
tele_test_knn_labels <- tele_norm[test_set, "yyes"]

library(class)
library(caret)

knnPred <- knn(train = tele_train_knn, test = tele_test_knn, cl = tele_train_knn_labels, k = 3)

library(gmodels)

CrossTable(x = tele_test_knn_labels, y = knnPred, prop.chisq = FALSE)

confusionMatrix(knnModel, as.factor(tele_test_knn_labels), positive = "1")
```


## LOGISTIC REGRESSION

```{r}

```


