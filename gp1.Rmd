---
title: "GP1 Telemarketing"
author: "Gino Assenmacher, , Nathan Koenig, Johanna Langemeyer, Lukas Resch, Benjamin Roemer"
date: "10/04/2022"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}

library(dplyr)

#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)

tele$pdays <- NULL
```

## Getting Data Ready for Analysis

```{r}

set.seed(12345)
tele_final_random <- tele[sample(nrow(tele)),]

# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

```

## Building a Clustering Model

```{r}

data_set_cluster <- tele_norm

yyesvalues <- data_set_cluster$yyes
data_set_cluster$yyes <- NULL

data_set_cluster <- as.data.frame(data_set_cluster)

set.seed(4222)
tele_clusters <- kmeans(data_set_cluster, 5)

library(ggpubr)
library(factoextra)

# fviz_cluster(tele_clusters, data = data_set_cluster,
#              palette = c("#2E9FDF", "#00AFBB", "#E7B800", "blue", "green"), 
#              geom = "point",
#              ellipse.type = "convex", 
#              ggtheme = theme_bw()
#              )

data_set_cluster$cluster <- tele_clusters$cluster
data_set_cluster$yyes <- yyesvalues

tapply(data_set_cluster$yyes, data_set_cluster$cluster, mean)


```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

```{r, cache=TRUE}

for (index in c(2,4,5)) {
  
  data_per_cluster <- data_set_cluster[data_set_cluster$cluster == index,]
  
  set.seed(4222)
  test_set_ann <- sample(1:nrow(data_per_cluster), round(nrow(data_per_cluster) * 0.2, 0))
  
  tele_train_ann <- data_per_cluster[-test_set_ann,]
  tele_test_ann <- data_per_cluster[test_set_ann,]
  
  library(neuralnet)
  
  ann_model <- neuralnet(formula = yyes ~ ., data = tele_train_ann, hidden = c(5,3))
  
  tele_test_ann$extra <- tele_test_ann$yyes
  tele_test_ann$yyes <- NULL
  names(tele_test_ann)[names(tele_test_ann) == 'extra'] <- "yyes" 
  
  ann_results <- neuralnet::compute(ann_model, tele_test_ann[1:53])
  
  predicted_strength <- ann_results$net.result
  
  prediction_ann <- predict(ann_model, tele_test_ann)
  yyes_prediction <- ifelse(prediction_ann < 0.5, 0, 1)
  
  cor(predicted_strength, tele_test_ann$yyes)
  
  assign(paste("ann_final_", index), yyes_prediction)

}

```

```{r}

library(class)
library(caret)
library(gmodels)

CrossTable(x = tele_test_ann$yyes, y = yyes_prediction, prop.chisq = FALSE)
confusionMatrix(as.factor(yyes_prediction), as.factor(tele_test_ann$yyes), positive = "1")

```

## KNN MODEL

```{r, cache=TRUE}

for (index in c(2,4,5)) {

  data_per_cluster <- data_set_cluster[data_set_cluster$cluster == index,]
  
  # Using model.matrix to convert all the factors to dummy variables
  # We are converting all of the factors into dummy variables as the input into knn has to be numeric
  
  # telemm <- as.data.frame(model.matrix(~.-1,data_per_cluster))
  
  telemm <- data_per_cluster
  
  # Randomize the rows in the data (shuffling the rows)
  set.seed(4222)
  tele_random <- telemm[sample(nrow(telemm)),]
  
  #Normalize the data
  normalize <- function(x) {
    return ((x - min(x)) / (max(x) - min(x)))
  }
  
  # we are going to normalize everything 
  # tele_norm <- as.data.frame(lapply(tele_random, normalize))
  
  tele_norm <- tele_random
  
  # Selects 10000 random rows for test data
  set.seed(4222)
  test_set <- sample(1:nrow(tele_norm), round(nrow(tele_norm) * 0.2, 0))
  # Depending on R-version and computer, different rows may be selected. 
  # If that happens, results are different. 
  
  # Create a train set and test set
  # First the predictors - all columns except the yyes column
  tele_train_knn <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
  tele_test_knn <- tele_norm[test_set, -match("yyes",names(tele_norm))]
  
  # tele_train_knn <- as.data.frame(scale(tele_train_knn))
  # tele_test_knn <- as.data.frame(scale(tele_test_knn))
  
  #Now the response (aka Labels) - only the yyes column
  tele_train_knn_labels <- tele_norm[-test_set, "yyes"]
  tele_test_knn_labels <- tele_norm[test_set, "yyes"]
  
  library(class)
  library(caret)
  
  knnPred <- knn(train = tele_train_knn, test = tele_test_knn, cl = tele_train_knn_labels, k = 3)
  
  library(gmodels)
  
  CrossTable(x = tele_test_knn_labels, y = knnPred, prop.chisq = FALSE)
  
  confusionMatrix(knnPred, as.factor(tele_test_knn_labels), positive = "1")
  
  assign(paste("knn_final_", index), as.data.frame(knnPred))
  
}
```


## LOGISTIC REGRESSION

```{r, cache=TRUE}

tele_final_random$cluster <- data_set_cluster$cluster

for (index in c(2,4,5)) {
  
  data_per_cluster <- tele_final_random[tele_final_random$cluster == index,]

  set.seed(4222)
  test_set_lr <- sample(1:nrow(data_per_cluster), round(nrow(data_per_cluster) * 0.2, 0))
  
  tele_train_lr <- data_per_cluster[-test_set_lr,]
  tele_test_lr <- data_per_cluster[test_set_lr,]
  
  tele_train_lr$y <- as.factor(tele_train_lr$y)
  
  lr_model <- glm(y ~ contact * month + campaign + pdaysdummy + poutcome + emp.var.rate + cons.price.idx + cons.conf.idx,
                  family = "binomial", data = tele_train_lr)
  
  lr_predict <- as.data.frame(predict(lr_model, newdata = tele_test_lr, type = "response"))
  lr_results <- ifelse(lr_predict$`predict(lr_model, newdata = tele_test_lr, type = "response")` > 0.25, 1, 0)
  
  library(class)
  library(caret)
  library(gmodels)
  
  tele_test_lr$V1 <- ifelse(tele_test_lr$y == "no", 0, 1)
  
  CrossTable(x = tele_test_lr$y, y = lr_results, prop.chisq = FALSE)
  confusionMatrix(as.factor(lr_results), as.factor(tele_test_lr$V1), positive = "1")
  
}

```

```{r}

ann_results <- yyes_prediction
knn_results <- ifelse(as.numeric(knnPred) > 1, 1, 0)
ann_results <- as.numeric(ann_results)

final_pred <- ifelse((lr_results + knn_results + ann_results) > 0, 1, 0)

CrossTable(x = tele_test_lr$y, y = final_pred, prop.chisq = FALSE)
confusionMatrix(as.factor(final_pred), as.factor(tele_test_lr$V1), positive = "1")

```

